{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbCRD_2u8NQk"
      },
      "source": [
        "# Sumário\n",
        "\n",
        "1. [Pré-Processamento](Pré)\n",
        "2. [Machine Learning](ml)\n",
        "3. [Gráficos](gf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ozcfCfUE2Bs"
      },
      "source": [
        "# Pré-Processamento dados Reais\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWRk8G3fB8Sx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSh0FwRoG4Jc"
      },
      "outputs": [],
      "source": [
        "\n",
        "df1 = pd.read_csv('https://raw.githubusercontent.com/GUIPETAV/Base/main/df1.csv')# falha de subcarga\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/GUIPETAV/Base/main/df2.csv')# sem falha de subcarga\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbTJIBbD3mS4"
      },
      "outputs": [],
      "source": [
        "df10 = pd.read_csv('https://raw.githubusercontent.com/GUIPETAV/Base/main/df10.csv') # falha de subcarga 10%\n",
        "df20 = pd.read_csv('https://raw.githubusercontent.com/GUIPETAV/Base/main/df20.csv') # falha de subcarga 20%\n",
        "df15 = pd.read_csv('https://raw.githubusercontent.com/GUIPETAV/Base/main/df15.csv') # falha de subcarga 15%\n",
        "dfbs = pd.read_csv('https://raw.githubusercontent.com/GUIPETAV/Base/main/dfbs.csv') #  sem de falha de subcarga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "3XoDbCXb4j8F",
        "outputId": "b39c26ac-7292-4473-a7af-7f6c859d3191"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Colunas do df2 com nomes diferentes do dfbs</th>\n",
              "      <th>Colunas do dfbs com nomes diferentes do df2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RTU_REFG_DISC_TEMP_2</td>\n",
              "      <td>RTU_OA_FLOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>date</td>\n",
              "      <td>RTU_STG_STA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RTU_REFG_SUCT_PRES_1</td>\n",
              "      <td>RTU_REFG_COND_TEMP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RTU_REFG_SUCT_TEMP_1</td>\n",
              "      <td>RTU_RA_FLOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RTU_REFG_DISC_TEMP_1</td>\n",
              "      <td>ZA_TEMP_SPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RTU_LA_COND_TEMP</td>\n",
              "      <td>RTU_TOT_CAPA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RTU_MA_TEMP</td>\n",
              "      <td>RTU_REFG_SUCT_PRES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RTU_MA_HUM</td>\n",
              "      <td>RTU_REFG_COND_PRES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RTU_REFG_SUCT_TEMP_2</td>\n",
              "      <td>RTU_REFG_DISC_TEMP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RTU_REFG_DISC_PRES_2</td>\n",
              "      <td>RTU_REFG_SUCT_TEMP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RTU_REFG_COND_TEMP_1</td>\n",
              "      <td>RTU_REFG_DISC_PRES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RTU_REFG_SUCT_PRES_2</td>\n",
              "      <td>RTU_SEN_CAPA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>RTU_REFG_COND_TEMP_2</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RTU_REFG_DISC_PRES_1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>time</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>month</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Colunas do df2 com nomes diferentes do dfbs  \\\n",
              "0                         RTU_REFG_DISC_TEMP_2   \n",
              "1                                         date   \n",
              "2                         RTU_REFG_SUCT_PRES_1   \n",
              "3                         RTU_REFG_SUCT_TEMP_1   \n",
              "4                         RTU_REFG_DISC_TEMP_1   \n",
              "5                             RTU_LA_COND_TEMP   \n",
              "6                                  RTU_MA_TEMP   \n",
              "7                                   RTU_MA_HUM   \n",
              "8                         RTU_REFG_SUCT_TEMP_2   \n",
              "9                         RTU_REFG_DISC_PRES_2   \n",
              "10                        RTU_REFG_COND_TEMP_1   \n",
              "11                        RTU_REFG_SUCT_PRES_2   \n",
              "12                        RTU_REFG_COND_TEMP_2   \n",
              "13                        RTU_REFG_DISC_PRES_1   \n",
              "14                                        time   \n",
              "15                                       month   \n",
              "\n",
              "   Colunas do dfbs com nomes diferentes do df2  \n",
              "0                                  RTU_OA_FLOW  \n",
              "1                                  RTU_STG_STA  \n",
              "2                           RTU_REFG_COND_TEMP  \n",
              "3                                  RTU_RA_FLOW  \n",
              "4                                  ZA_TEMP_SPT  \n",
              "5                                 RTU_TOT_CAPA  \n",
              "6                           RTU_REFG_SUCT_PRES  \n",
              "7                           RTU_REFG_COND_PRES  \n",
              "8                           RTU_REFG_DISC_TEMP  \n",
              "9                           RTU_REFG_SUCT_TEMP  \n",
              "10                          RTU_REFG_DISC_PRES  \n",
              "11                                RTU_SEN_CAPA  \n",
              "12                                        None  \n",
              "13                                        None  \n",
              "14                                        None  \n",
              "15                                        None  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Obter os nomes das colunas de ambos os DataFrames\n",
        "columns_df2 = set(df2.columns)\n",
        "columns_dfbs = set(dfbs.columns)\n",
        "\n",
        "# Encontrar as colunas com nomes diferentes\n",
        "different_columns_df2 = columns_df2.difference(columns_dfbs)\n",
        "different_columns_dfbs = columns_dfbs.difference(columns_df2)\n",
        "\n",
        "# Criar listas vazias para as colunas do DataFrame\n",
        "different_columns_df2_list = list(different_columns_df2)\n",
        "different_columns_dfbs_list = list(different_columns_dfbs)\n",
        "\n",
        "# Preencher com None para manter as listas com o mesmo tamanho\n",
        "max_length = max(len(different_columns_df2_list), len(different_columns_dfbs_list))\n",
        "different_columns_df2_list.extend([None] * (max_length - len(different_columns_df2_list)))\n",
        "different_columns_dfbs_list.extend([None] * (max_length - len(different_columns_dfbs_list)))\n",
        "\n",
        "# Criar um DataFrame para a tabela\n",
        "table_data = {\n",
        "    'Colunas do df2 com nomes diferentes do dfbs': different_columns_df2_list,\n",
        "    'Colunas do dfbs com nomes diferentes do df2': different_columns_dfbs_list\n",
        "}\n",
        "\n",
        "result_table = pd.DataFrame(table_data)\n",
        "\n",
        "\n",
        "result_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THYdm66H50ii"
      },
      "outputs": [],
      "source": [
        "# Remover as features incongruentes\n",
        "\n",
        "columns_to_drop_real = ['Unnamed: 0','time','date','month'\n",
        "    'RTU_MA_HUM', 'RTU_MA_TEMP', 'RTU_LA_COND_TEMP',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SGMxIiqLU39"
      },
      "outputs": [],
      "source": [
        "df1_t = df1.assign(Target = 1) # falha de subcarga\n",
        "\n",
        "df2_t = df2.assign(Target = 0) # não falha de subcarga\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFfhB98XRqk8"
      },
      "outputs": [],
      "source": [
        "# Eliminando  os momentos de desligameno do sistema no  site 2 de forma continua\n",
        "# Seleciona as linhas que não contêm zero na FAN_WAAT e 'COMP_WATT'.\n",
        "\n",
        "df1_c = df1_t.loc[(df1_t['RTU_SA_FAN_WATT'] != 0) & (df1_t['RTU_COMP_WATT'] != 0)]\n",
        "df2_c = df2_t.loc[(df2_t['RTU_SA_FAN_WATT'] != 0) & (df2_t['RTU_COMP_WATT'] != 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFFu2OEAxpGc"
      },
      "outputs": [],
      "source": [
        "# Cria uma nova feature com a soma das pressões\n",
        "df1_c = df1_c.assign(\n",
        "    RTU_REFG_DISC_PRES=df1_c['RTU_REFG_DISC_PRES_1'] + df1_c['RTU_REFG_DISC_PRES_2'],\n",
        "    RTU_REFG_SUCT_PRES=df1_c['RTU_REFG_SUCT_PRES_1'] + df1_c['RTU_REFG_SUCT_PRES_2'],\n",
        "    RTU_REFG_COND_TEMP=df1_c['RTU_REFG_COND_TEMP_1'] + df1_c['RTU_REFG_COND_TEMP_2'],\n",
        "    RTU_REFG_SUCT_TEMP=df1_c['RTU_REFG_SUCT_TEMP_1'] + df1_c['RTU_REFG_SUCT_TEMP_2'],\n",
        "    RTU_REFG_DISC_TEMP=df1_c['RTU_REFG_DISC_TEMP_1'] + df1_c['RTU_REFG_DISC_TEMP_2'])\n",
        "\n",
        "df2_c = df2_c.assign(\n",
        "    RTU_REFG_DISC_PRES=df2_c['RTU_REFG_DISC_PRES_1'] + df2_c['RTU_REFG_DISC_PRES_2'],\n",
        "    RTU_REFG_SUCT_PRES=df2_c['RTU_REFG_SUCT_PRES_1'] + df2_c['RTU_REFG_SUCT_PRES_2'],\n",
        "    RTU_REFG_COND_TEMP=df2_c['RTU_REFG_COND_TEMP_1'] + df2_c['RTU_REFG_COND_TEMP_2'],\n",
        "    RTU_REFG_SUCT_TEMP=df2_c['RTU_REFG_SUCT_TEMP_1'] + df2_c['RTU_REFG_SUCT_TEMP_2'],\n",
        "    RTU_REFG_DISC_TEMP=df2_c['RTU_REFG_DISC_TEMP_1'] + df2_c['RTU_REFG_DISC_TEMP_2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4DwMtUmGi3j"
      },
      "outputs": [],
      "source": [
        "# Elimina as features\n",
        "columns_to_drop = ['Unnamed: 0',\n",
        "    'RTU_MA_HUM', 'RTU_MA_TEMP', 'RTU_LA_COND_TEMP',\n",
        "    'RTU_REFG_DISC_PRES_1', 'RTU_REFG_DISC_PRES_2',\n",
        "    'RTU_REFG_SUCT_PRES_1', 'RTU_REFG_SUCT_PRES_2',\n",
        "    'RTU_REFG_COND_TEMP_1', 'RTU_REFG_COND_TEMP_2',\n",
        "    'RTU_REFG_SUCT_TEMP_1', 'RTU_REFG_SUCT_TEMP_2',\n",
        "    'RTU_REFG_DISC_TEMP_1', 'RTU_REFG_DISC_TEMP_2',\n",
        "]\n",
        "\n",
        "df1_x = df1_c.drop(columns_to_drop, axis=1)\n",
        "df2_x = df2_c.drop(columns_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrmXc9uFCxm5"
      },
      "outputs": [],
      "source": [
        "# Converter fahrenheit para celsius\n",
        "def fahrenheit_to_celsius(fahrenheit):\n",
        "    celsius = (fahrenheit - 32) * 5/9\n",
        "    return celsius\n",
        "\n",
        "# Colunas a serem convertidas\n",
        "columns_to_convert = ['RTU_RA_TEMP', 'RTU_OA_TEMP', 'ZA_TEMP', 'RTU_REFG_COND_TEMP',\n",
        "                      'RTU_REFG_SUCT_TEMP', 'RTU_REFG_DISC_TEMP','RTU_SA_TEMP']\n",
        "\n",
        "\n",
        "# Aplicando a conversão para Celsius\n",
        "df20[columns_to_convert] = df20[columns_to_convert].apply(fahrenheit_to_celsius)\n",
        "dfbs[columns_to_convert] = dfbs[columns_to_convert].apply(fahrenheit_to_celsius)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtXQsCXFFV3_"
      },
      "outputs": [],
      "source": [
        "# Converter colunas de Pascal para Bar\n",
        "df20['RTU_REFG_SUCT_PRES'], df20['RTU_REFG_DISC_PRES'] = df20['RTU_REFG_SUCT_PRES'] /100000 , df20['RTU_REFG_DISC_PRES'] /100000\n",
        "dfbs['RTU_REFG_SUCT_PRES'], dfbs['RTU_REFG_DISC_PRES'] = dfbs['RTU_REFG_SUCT_PRES'] / 100000, dfbs['RTU_REFG_DISC_PRES'] /100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv83qY5YtxeY"
      },
      "outputs": [],
      "source": [
        "\n",
        "df20_t = df20.assign(Target = 1) # falha de subcarga\n",
        "\n",
        "dfbs_t = dfbs.assign(Target = 0) #  não falha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzXToH-owerq"
      },
      "outputs": [],
      "source": [
        "# Eliminando  os momentos de desligameno do sistema no  site 2 de forma continua\n",
        "# Seleciona as linhas que não contêm zero na FAN_WAAT e 'COMP_WATT'.\n",
        "\n",
        "df20_c = df20_t.loc[(df20_t['RTU_COMP_WATT'] != 0) ]\n",
        "dfbs_c = dfbs_t.loc[(dfbs_t['RTU_COMP_WATT'] != 0) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC3ZGGEM_hYg"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['Unnamed: 0',\n",
        "    'RTU_RA_FLOW', 'RTU_OA_FLOW', 'RTU_STG_STA',\n",
        "    'RTU_REFG_COND_PRES', 'RTU_SEN_CAPA',\n",
        "    'RTU_TOT_CAPA', 'ZA_TEMP_SPT',\n",
        "]\n",
        "\n",
        "df20_c = df20_c.drop(columns_to_drop, axis=1)\n",
        "dfbs_c = dfbs_c.drop(columns_to_drop, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15kgpxbiAuDB"
      },
      "outputs": [],
      "source": [
        "# Definir y real\n",
        "\n",
        "df1_y= df1_c['Target']\n",
        "df2_y= df2_c['Target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCtpfDxtE8_l"
      },
      "outputs": [],
      "source": [
        "# Definir X real\n",
        "df1_x= df1_x.drop(['Datetime','Target'], axis=1)\n",
        "df2_x= df2_x.drop(['Datetime','Target'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19SfsiEQVHHa"
      },
      "outputs": [],
      "source": [
        "# # Definir X real sem features modificadas\n",
        "# df1_x= df1_x.drop(['Datetime','Target','RTU_RA_TEMP','RTU_OA_TEMP','ZA_TEMP', 'RTU_REFG_COND_TEMP', 'RTU_REFG_SUCT_TEMP', 'RTU_REFG_DISC_TEMP','RTU_SA_TEMP','RTU_REFG_SUCT_PRES','RTU_REFG_DISC_PRES'], axis=1)\n",
        "# df2_x= df2_x.drop(['Datetime','Target','RTU_RA_TEMP','RTU_OA_TEMP','ZA_TEMP', 'RTU_REFG_COND_TEMP', 'RTU_REFG_SUCT_TEMP', 'RTU_REFG_DISC_TEMP','RTU_SA_TEMP','RTU_REFG_SUCT_PRES','RTU_REFG_DISC_PRES'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN611DS7I75V"
      },
      "outputs": [],
      "source": [
        "# Definir X sim\n",
        "\n",
        "df20_x= df20_c.drop(['Datetime','Target'], axis=1)\n",
        "dfbs_x= dfbs_c.drop(['Datetime','Target'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWLlj4KqFN27"
      },
      "outputs": [],
      "source": [
        "# # Definir X sim sem features modificadas\n",
        "\n",
        "# df20_x= df20_c.drop(['Datetime','Target','RTU_RA_TEMP','RTU_OA_TEMP','ZA_TEMP', 'RTU_REFG_COND_TEMP', 'RTU_REFG_SUCT_TEMP', 'RTU_REFG_DISC_TEMP','RTU_SA_TEMP','RTU_REFG_SUCT_PRES','RTU_REFG_DISC_PRES'], axis=1)\n",
        "# dfbs_x= dfbs_c.drop(['Datetime','Target','RTU_RA_TEMP','RTU_OA_TEMP','ZA_TEMP', 'RTU_REFG_COND_TEMP', 'RTU_REFG_SUCT_TEMP', 'RTU_REFG_DISC_TEMP','RTU_SA_TEMP','RTU_REFG_SUCT_PRES','RTU_REFG_DISC_PRES'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GufWhQKXHbrh"
      },
      "outputs": [],
      "source": [
        "# Definir y sim\n",
        "\n",
        "df20_y = df20_c['Target']\n",
        "dfbs_y = dfbs_c['Target']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iUDuIoWz6yO"
      },
      "source": [
        "### Avaliar as temperaturas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf84XydE12Tw",
        "outputId": "8451a82e-f9f8-4f00-9476-26b797c49d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colunas TEMP de df1_x: ['RTU_OA_TEMP', 'RTU_RA_TEMP', 'RTU_SA_TEMP', 'ZA_TEMP']\n",
            "Colunas TEMP de df2_x: ['RTU_OA_TEMP', 'RTU_RA_TEMP', 'RTU_SA_TEMP', 'ZA_TEMP']\n",
            "Colunas TEMP de df20_x: ['RTU_OA_TEMP', 'RTU_RA_TEMP', 'RTU_SA_TEMP', 'ZA_TEMP']\n",
            "Colunas TEMP de dfbs_x: ['RTU_OA_TEMP', 'RTU_RA_TEMP', 'RTU_SA_TEMP', 'ZA_TEMP']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Lista de nomes dos DataFrames\n",
        "df_names = ['df1_x', 'df2_x', 'df20_x', 'dfbs_x']\n",
        "\n",
        "# Dicionário para armazenar as colunas de cada DataFrame que terminam com \"TEMP\"\n",
        "temp_columns_dict = {}\n",
        "\n",
        "# Loop pelos nomes dos DataFrames\n",
        "for df_name in df_names:\n",
        "    df = globals()[df_name]  # Obtém o DataFrame pelo nome\n",
        "    temp_columns = [col for col in df.columns if col.endswith('TEMP')]\n",
        "    temp_columns_dict[df_name] = temp_columns\n",
        "\n",
        "# Mostrar as colunas TEMP de cada DataFrame\n",
        "for df_name, temp_columns in temp_columns_dict.items():\n",
        "    print(f\"Colunas TEMP de {df_name}: {temp_columns}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJKMZER82Nqi",
        "outputId": "a14839bf-ffcc-4171-de9d-c153a29f20c1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Lista de nomes dos DataFrames\n",
        "df_names = ['df1_x', 'df2_x', 'df20_x', 'dfbs_x']\n",
        "\n",
        "# Dicionário para armazenar os novos DataFrames\n",
        "new_df_dict = {}\n",
        "\n",
        "# Loop pelos nomes dos DataFrames\n",
        "for df_name in df_names:\n",
        "    df = globals()[df_name]  # Obtém o DataFrame pelo nome\n",
        "    temp_columns = [col for col in df.columns if col.endswith('TEMP')]\n",
        "    new_df = df[temp_columns].copy()  # Cria um novo DataFrame com as colunas TEMP\n",
        "    new_df_dict[df_name] = new_df\n",
        "\n",
        "# Mostrar os novos DataFrames\n",
        "for df_name, new_df in new_df_dict.items():\n",
        "    print(f\"Novo DataFrame {df_name}:\")\n",
        "    print(new_df)\n",
        "\n",
        "    new_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpPsv_eJw0hH"
      },
      "source": [
        "# Ordenar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i6MaEg4dze0"
      },
      "outputs": [],
      "source": [
        "colunas_df1_x = set(df1_x.columns)\n",
        "colunas_df2_x = set(df2_x.columns)\n",
        "colunas_df20_x = set(df20_x.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUxwS7P-d-sf",
        "outputId": "874e490e-abe3-49bc-d97b-7e09ca5f6142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Os nomes das colunas correspondem.\n"
          ]
        }
      ],
      "source": [
        "if colunas_df1_x == colunas_df20_x:\n",
        "    print(\"Os nomes das colunas correspondem.\")\n",
        "else:\n",
        "    print(\"Os nomes das colunas não correspondem.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmoweTvw2sLu",
        "outputId": "cb9117ca-2ddf-4906-94df-6af6e0d92954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Os nomes das colunas não correspondem.\n"
          ]
        }
      ],
      "source": [
        "if colunas_df2_x == colunas_df20_x:\n",
        "    print(\"Os nomes das colunas correspondem.\")\n",
        "else:\n",
        "    print(\"Os nomes das colunas não correspondem.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyJMlPHLgeD1"
      },
      "outputs": [],
      "source": [
        "sequencia_colunas = df20_x.columns\n",
        "df1_x = df1_x[sequencia_colunas]\n",
        "df2_x = df2_x[sequencia_colunas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rmdgj4O3RYQ",
        "outputId": "4cb225f0-bbe2-4408-86d7-a31c4813b44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 142476 entries, 0 to 143940\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   RTU_COMP_WATT       142476 non-null  float64\n",
            " 1   RTU_OA_HUM          142476 non-null  float64\n",
            " 2   RTU_OA_TEMP         142476 non-null  float64\n",
            " 3   RTU_RA_HUM          142476 non-null  float64\n",
            " 4   RTU_RA_TEMP         142476 non-null  float64\n",
            " 5   RTU_REFG_DISC_PRES  142476 non-null  float64\n",
            " 6   RTU_REFG_SUCT_PRES  142476 non-null  float64\n",
            " 7   RTU_SA_FAN_WATT     142476 non-null  float64\n",
            " 8   RTU_SA_FLOW         142476 non-null  float64\n",
            " 9   RTU_SA_HUM          142476 non-null  float64\n",
            " 10  RTU_SA_TEMP         142476 non-null  float64\n",
            " 11  RTU_TOT_WATT        142476 non-null  float64\n",
            " 12  ZA_HUM              142476 non-null  float64\n",
            " 13  ZA_TEMP             142476 non-null  float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 16.3 MB\n"
          ]
        }
      ],
      "source": [
        "dfbs_x.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E78FvuK7zg_C",
        "outputId": "06c64b52-e380-4446-e750-1431a3b1d8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 143084 entries, 0 to 143940\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   RTU_COMP_WATT       143084 non-null  float64\n",
            " 1   RTU_OA_HUM          143084 non-null  float64\n",
            " 2   RTU_OA_TEMP         143084 non-null  float64\n",
            " 3   RTU_RA_HUM          143084 non-null  float64\n",
            " 4   RTU_RA_TEMP         143084 non-null  float64\n",
            " 5   RTU_REFG_DISC_PRES  143084 non-null  float64\n",
            " 6   RTU_REFG_SUCT_PRES  143084 non-null  float64\n",
            " 7   RTU_SA_FAN_WATT     143084 non-null  float64\n",
            " 8   RTU_SA_FLOW         143084 non-null  float64\n",
            " 9   RTU_SA_HUM          143084 non-null  float64\n",
            " 10  RTU_SA_TEMP         143084 non-null  float64\n",
            " 11  RTU_TOT_WATT        143084 non-null  float64\n",
            " 12  ZA_HUM              143084 non-null  float64\n",
            " 13  ZA_TEMP             143084 non-null  float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 16.4 MB\n"
          ]
        }
      ],
      "source": [
        "df20_x.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu8jpVnLzWB2",
        "outputId": "2fffe047-a79e-4c8a-c11b-90ad9d9c36d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 11688 entries, 2325 to 41460\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   RTU_COMP_WATT       11688 non-null  float64\n",
            " 1   RTU_OA_HUM          11688 non-null  float64\n",
            " 2   RTU_OA_TEMP         11688 non-null  float64\n",
            " 3   RTU_RA_HUM          11688 non-null  float64\n",
            " 4   RTU_RA_TEMP         11688 non-null  float64\n",
            " 5   RTU_REFG_DISC_PRES  11688 non-null  float64\n",
            " 6   RTU_REFG_SUCT_PRES  11688 non-null  float64\n",
            " 7   RTU_SA_FAN_WATT     11688 non-null  float64\n",
            " 8   RTU_SA_FLOW         11688 non-null  float64\n",
            " 9   RTU_SA_HUM          11688 non-null  float64\n",
            " 10  RTU_SA_TEMP         11688 non-null  float64\n",
            " 11  RTU_TOT_WATT        11688 non-null  float64\n",
            " 12  ZA_HUM              11688 non-null  float64\n",
            " 13  ZA_TEMP             11688 non-null  float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 1.3 MB\n"
          ]
        }
      ],
      "source": [
        "df1_x.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1sfr360240I",
        "outputId": "868c5f3a-c9e4-4b2f-c42e-0b35a5727389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 102705 entries, 251 to 258583\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   RTU_COMP_WATT       102705 non-null  float64\n",
            " 1   RTU_OA_HUM          102705 non-null  float64\n",
            " 2   RTU_OA_TEMP         102705 non-null  float64\n",
            " 3   RTU_RA_HUM          102705 non-null  float64\n",
            " 4   RTU_RA_TEMP         102705 non-null  float64\n",
            " 5   RTU_REFG_DISC_PRES  102705 non-null  float64\n",
            " 6   RTU_REFG_SUCT_PRES  102705 non-null  float64\n",
            " 7   RTU_SA_FAN_WATT     102705 non-null  float64\n",
            " 8   RTU_SA_FLOW         102705 non-null  float64\n",
            " 9   RTU_SA_HUM          102705 non-null  float64\n",
            " 10  RTU_SA_TEMP         102705 non-null  float64\n",
            " 11  RTU_TOT_WATT        102705 non-null  float64\n",
            " 12  ZA_HUM              102705 non-null  float64\n",
            " 13  ZA_TEMP             102705 non-null  float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 11.8 MB\n"
          ]
        }
      ],
      "source": [
        "df2_x.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyJPdnRCtrXX"
      },
      "source": [
        "# cross validation real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GT-YUtuzpdT"
      },
      "outputs": [],
      "source": [
        "# separar X falha\n",
        "num_linhas = len(df1_x)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "# Separe o dataframe em cinco partes e criar uma lista\n",
        "X1 = [df1_x.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Ka-ZzIJdz7"
      },
      "outputs": [],
      "source": [
        "# separar y falha\n",
        "num_linhas = len(df1_y)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "# Separe o dataframe em cinco partes e criar uma lista\n",
        "\n",
        "y1 = [df1_y.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2RAu-7kJqk3"
      },
      "outputs": [],
      "source": [
        "#separar X nfalha\n",
        "\n",
        "num_linhas = len(df2_x)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "# Separe o dataframe em cinco partes e criar uma lista\n",
        "X2 = [df2_x.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjvhxvHsKB4y"
      },
      "outputs": [],
      "source": [
        "# separar y nfalha\n",
        "\n",
        "num_linhas = len(df2_y)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "# Separe o dataframe em cinco partes e criar uma lista\n",
        "y2 = [df2_y.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNaaCkLDx197",
        "outputId": "ccf9a522-9e8a-49db-f6ae-6bb270b414f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de combinações possíveis: 25\n"
          ]
        }
      ],
      "source": [
        "# Combinações Possíveis\n",
        "total_combinacoes = len(X1) * len(X2)\n",
        "print(\"Total de combinações possíveis:\", total_combinacoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDMcFhJgiTdV"
      },
      "outputs": [],
      "source": [
        "combinacoes_X = []\n",
        "combinacoes_y = []\n",
        "\n",
        "for i1 in range(len(X1)):\n",
        "    for i2 in range(len(X2)):\n",
        "        X_teste = pd.concat([X1[i] for i in range(len(X1)) if i == i1] + [X2[j] for j in range(len(X2)) if j == i2])\n",
        "        X_treino = pd.concat([X1[i] for i in range(len(X1)) if i != i1] + [X2[j] for j in range(len(X2)) if j != i2])\n",
        "        combinacoes_X.append((X_teste, X_treino))\n",
        "\n",
        "for i1 in range(len(y1)):\n",
        "    for i2 in range(len(y2)):\n",
        "        y_teste = pd.concat([y1[i] for i in range(len(y1)) if i == i1] + [y2[j] for j in range(len(y2)) if j == i2])\n",
        "        y_treino = pd.concat([y1[i] for i in range(len(y1)) if i != i1] + [y2[j] for j in range(len(y2)) if j != i2])\n",
        "        combinacoes_y.append((y_teste, y_treino))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIjB02UurlL"
      },
      "source": [
        "# Cross simulado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGq0K8unKYqc"
      },
      "outputs": [],
      "source": [
        "# separar y nfalha\n",
        "\n",
        "num_linhas = len(df20_y)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "num_linhas = len(dfbs_y)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "\n",
        "# Separe o dataframe em cinco partes e criar uma lista\n",
        "\n",
        "y20 = [df20_y.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]\n",
        "\n",
        "ybs= [dfbs_y.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LMtCu-5QuPb",
        "outputId": "4d58510a-30a5-4977-809f-661641d0e4a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de combinações possíveis: 25\n"
          ]
        }
      ],
      "source": [
        "total_combinacoes = len(y20) * len(ybs)\n",
        "print(\"Total de combinações possíveis:\", total_combinacoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDGQdc4nKYqd"
      },
      "outputs": [],
      "source": [
        "#separar X nfalha\n",
        "\n",
        "num_linhas = len(df20_x)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "num_linhas = len(dfbs_x)\n",
        "tamanho_parte = num_linhas // 5\n",
        "\n",
        "# Separe o dataframe em cinco partes e criar uma lista\n",
        "\n",
        "X20 = [df20_x.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]\n",
        "\n",
        "Xbs= [dfbs_x.iloc[(i*tamanho_parte):((i+1)*tamanho_parte)] for i in range(5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wevKMBvxKYqf",
        "outputId": "2584d8c9-3819-4dcc-c27a-aedbd280acdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de combinações possíveis: 25\n"
          ]
        }
      ],
      "source": [
        "total_combinacoes = len(X20) * len(Xbs)\n",
        "print(\"Total de combinações possíveis:\", total_combinacoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYGHeV0VNMzY"
      },
      "outputs": [],
      "source": [
        "combinacoes_Xs = []\n",
        "combinacoes_ys = []\n",
        "\n",
        "for i1 in range(len(X20)):\n",
        "    for i2 in range(len(Xbs)):\n",
        "        Xs_teste = pd.concat([X20[i] for i in range(len(X20)) if i == i1] + [Xbs[j] for j in range(len(Xbs)) if j == i2])\n",
        "        Xs_treino = pd.concat([X20[i] for i in range(len(X20)) if i != i1] + [Xbs[j] for j in range(len(Xbs)) if j != i2])\n",
        "        combinacoes_Xs.append((Xs_teste, Xs_treino))\n",
        "\n",
        "for i1 in range(len(y20)):\n",
        "    for i2 in range(len(ybs)):\n",
        "        ys_teste = pd.concat([y20[i] for i in range(len(y20)) if i == i1] + [ybs[j] for j in range(len(ybs)) if j == i2])\n",
        "        ys_treino = pd.concat([y20[i] for i in range(len(y20)) if i != i1] + [ybs[j] for j in range(len(ybs)) if j != i2])\n",
        "        combinacoes_ys.append((ys_teste, ys_treino))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFzgGFjGvzG"
      },
      "source": [
        "# Combinação Simulado_Real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1naFpw7TrOeJ"
      },
      "outputs": [],
      "source": [
        "combinacoes_Xsr = []\n",
        "combinacoes_ysr = []\n",
        "\n",
        "for i1 in range(len(X20)):\n",
        "    for i2 in range(len(Xbs)):\n",
        "        Xsr_teste = pd.concat([X1[i] for i in range(len(X1)) if i == i1] + [X2[j] for j in range(len(X2)) if j == i2])\n",
        "        Xsr_treino = pd.concat([X20[i] for i in range(len(X20)) if i != i1] + [Xbs[j] for j in range(len(Xbs)) if j != i2])\n",
        "        combinacoes_Xsr.append((Xsr_teste, Xsr_treino))\n",
        "\n",
        "for i1 in range(len(y20)):\n",
        "    for i2 in range(len(ybs)):\n",
        "        ysr_teste = pd.concat([y1[i] for i in range(len(y1)) if i == i1] + [y2[j] for j in range(len(y2)) if j == i2])\n",
        "        ysr_treino = pd.concat([y20[i] for i in range(len(y20)) if i != i1] + [ybs[j] for j in range(len(ybs)) if j != i2])\n",
        "        combinacoes_ysr.append((ysr_teste, ysr_treino))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFtU_6bNr29z"
      },
      "source": [
        "#Modelos Preditivos(Classificadores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgI4a_4NYJH_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.ensemble import (AdaBoostClassifier,\n",
        "                              GradientBoostingClassifier,\n",
        "                              ExtraTreesClassifier,\n",
        "                              RandomForestClassifier)\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbciO0NMX-2G"
      },
      "source": [
        "\n",
        "\n",
        "### Classificador real/real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM1R-ZhaYRW1",
        "outputId": "950303a4-8523-47fe-cdc1-efca8f2005da"
      },
      "outputs": [],
      "source": [
        "class ModeloAuxiliar1(object):\n",
        "    def __init__(self, clf, seed=27, params=None):\n",
        "        if params:\n",
        "            params['random_state'] = seed\n",
        "            self.clf = clf(**params)\n",
        "        else:\n",
        "            self.clf = clf()\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        return self.clf.fit(x, y)\n",
        "\n",
        "    def feature_importances(self, x, y):\n",
        "        return self.clf.fit(x, y).feature_importances_\n",
        "\n",
        "modelos = [{'nome': 'logreg',\n",
        "           'modelo': LogisticRegression},\n",
        "           {'nome': 'KNN',\n",
        "            'modelo': KNeighborsClassifier},\n",
        "           {'nome': 'GaussianNB',\n",
        "            'modelo': GaussianNB},\n",
        "           {'nome': 'Perceptron',\n",
        "           'modelo': Perceptron},\n",
        "           {'nome': 'LinearSVC',\n",
        "            'modelo': LinearSVC},\n",
        "           {'nome': 'SGD',\n",
        "            'modelo': SGDClassifier},\n",
        "           {'nome': 'Dtree',\n",
        "            'modelo': DecisionTreeClassifier},\n",
        "           {'nome': 'RForest',\n",
        "            'modelo': RandomForestClassifier},\n",
        "           {'nome': 'ADA',\n",
        "            'modelo': AdaBoostClassifier},\n",
        "           {'nome': 'GBC',\n",
        "            'modelo': GradientBoostingClassifier},\n",
        "           {'nome': 'ETC',\n",
        "            'modelo': ExtraTreesClassifier},\n",
        "\n",
        "          ]\n",
        "\n",
        "resultados1 = []\n",
        "medias_acuracias1 = []\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(len(combinacoes_X)):\n",
        "    X_teste, X_treino = combinacoes_X[i]\n",
        "    y_teste, y_treino = combinacoes_y[i]\n",
        "\n",
        "    X_treino_scaled = scaler.fit_transform(X_treino)\n",
        "    X_teste_scaled = scaler.transform(X_teste)\n",
        "\n",
        "    acuracias = []\n",
        "\n",
        "    for model in modelos:\n",
        "        x = ModeloAuxiliar1(clf=model['modelo'])\n",
        "\n",
        "        # treinar o modelo\n",
        "        x.fit(X_treino_scaled, y_treino)\n",
        "\n",
        "        # gerar previsão\n",
        "        y_pred = x.predict(X_teste_scaled)\n",
        "\n",
        "        # calcular a acurácia\n",
        "        acuracia = accuracy_score(y_teste, y_pred)\n",
        "\n",
        "        acuracias.append(acuracia)\n",
        "\n",
        "       # Calcular a acurácia balanceada\n",
        "\n",
        "        acuracia_balanceada = balanced_accuracy_score(y_teste, y_pred)\n",
        "\n",
        "       # Calcular a f1 balanceada\n",
        "\n",
        "        f1_balanceada = f= f1_score(y_teste, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "        # calcular as demais métricas\n",
        "        precisao = precision_score(y_teste, y_pred)\n",
        "        recall = recall_score(y_teste, y_pred)\n",
        "        f1 = f1_score(y_teste, y_pred)\n",
        "        matriz_confusao = confusion_matrix(y_teste, y_pred)\n",
        "\n",
        "\n",
        "        resultados1.append({'Nome': model['nome'],\n",
        "                           'Acurácia': acuracia,\n",
        "                           'Acurácia Balanceada': acuracia_balanceada,\n",
        "                           'Precisão': precisao,\n",
        "                           'Recall': recall,\n",
        "                           'F1-score': f1,\n",
        "                           'F1-score Balanceada': f1_balanceada,\n",
        "                           'Matriz de Confusão': matriz_confusao,\n",
        "                           'Predição': y_pred\n",
        "                           })\n",
        "\n",
        "        # Salvar o modelo treinado usando joblib\n",
        "        model_filename = f\"modelo_{model['nome']}_treinado_real_0.joblib\"\n",
        "        joblib.dump(x, model_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LZ_cmVYNYkcy",
        "outputId": "63f36221-150f-4e42-dac5-ecdefb216501"
      },
      "outputs": [],
      "source": [
        "modelos_df1 = pd.DataFrame(resultados1)\n",
        "modelos_df1 = modelos_df1[['Nome', 'Acurácia','Acurácia Balanceada','Precisão', 'Recall', 'F1-score','F1-score Balanceada', 'Matriz de Confusão','Predição']]\n",
        "\n",
        "\n",
        "modelos_df1.head()\n",
        "\n",
        "modelos_df1.to_csv('modelos_real_real_0.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS1Fz3HB2s_B"
      },
      "outputs": [],
      "source": [
        "#carregar = joblib.load('modelo_ETC_treinado.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Nc7Sw3Fn5NGj",
        "outputId": "b52617a6-9afc-46fd-fbf2-c80214b94f37"
      },
      "outputs": [],
      "source": [
        "#X_teste.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP-XSDL540Pw",
        "outputId": "1e84c532-17ff-42d9-f03e-460fb2f9f5d7"
      },
      "outputs": [],
      "source": [
        "#carregar.predict( X_teste.head(60).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBPyMoNs6jal",
        "outputId": "7d993db2-f25f-49c7-c51f-50473ce7bc06"
      },
      "outputs": [],
      "source": [
        "#y_teste.head(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAfLiRoU9FSx"
      },
      "source": [
        "### Classificador sim/sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWbUtz6oZ8s8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/guilherme/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class ModeloAuxiliar2(object):\n",
        "    def __init__(self, clf, seed=27, params=None):\n",
        "        if params:\n",
        "            params['random_state'] = seed\n",
        "            self.clf = clf(**params)\n",
        "        else:\n",
        "            self.clf = clf()\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        return self.clf.fit(x, y)\n",
        "\n",
        "    def feature_importances(self, x, y):\n",
        "        return self.clf.fit(x, y).feature_importances_\n",
        "\n",
        "modelos = [{'nome': 'logreg',\n",
        "           'modelo': LogisticRegression},\n",
        "           {'nome': 'KNN',\n",
        "            'modelo': KNeighborsClassifier},\n",
        "           {'nome': 'GaussianNB',\n",
        "            'modelo': GaussianNB},\n",
        "           {'nome': 'Perceptron',\n",
        "           'modelo': Perceptron},\n",
        "           {'nome': 'LinearSVC',\n",
        "            'modelo': LinearSVC},\n",
        "           {'nome': 'SGD',\n",
        "            'modelo': SGDClassifier},\n",
        "           {'nome': 'Dtree',\n",
        "            'modelo': DecisionTreeClassifier},\n",
        "           {'nome': 'RForest',\n",
        "            'modelo': RandomForestClassifier},\n",
        "           {'nome': 'ADA',\n",
        "            'modelo': AdaBoostClassifier},\n",
        "           {'nome': 'GBC',\n",
        "            'modelo': GradientBoostingClassifier},\n",
        "           {'nome': 'ETC',\n",
        "            'modelo': ExtraTreesClassifier},\n",
        "\n",
        "          ]\n",
        "\n",
        "resultados2 = []\n",
        "medias_acuracias2 = []\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(len(combinacoes_Xs)):\n",
        "    X_teste, X_treino = combinacoes_Xs[i]\n",
        "    y_teste, y_treino = combinacoes_ys[i]\n",
        "\n",
        "    X_treino_scaled = scaler.fit_transform(X_treino)\n",
        "    X_teste_scaled = scaler.transform(X_teste)\n",
        "\n",
        "    acuracias = []\n",
        "\n",
        "    for model in modelos:\n",
        "        x = ModeloAuxiliar1(clf=model['modelo'])\n",
        "\n",
        "        # treinar o modelo\n",
        "        x.fit(X_treino_scaled, y_treino)\n",
        "\n",
        "        # gerar previsão\n",
        "        y_pred = x.predict(X_teste_scaled)\n",
        "\n",
        "        # calcular a acurácia\n",
        "        acuracia = accuracy_score(y_teste, y_pred)\n",
        "\n",
        "        acuracias.append(acuracia)\n",
        "\n",
        "       # Calcula a acurácia balanceada\n",
        "\n",
        "        acuracia_balanceada = balanced_accuracy_score(y_teste, y_pred)\n",
        "        # Calcular a f1 balanceada\n",
        "\n",
        "        f1_balanceada = f= f1_score(y_teste, y_pred, average='weighted')\n",
        "\n",
        "        # calcular as demaism métricas\n",
        "        precisao = precision_score(y_teste, y_pred)\n",
        "        recall = recall_score(y_teste, y_pred)\n",
        "        f1 = f1_score(y_teste, y_pred)\n",
        "        matriz_confusao = confusion_matrix(y_teste, y_pred)\n",
        "\n",
        "        resultados2.append({'Nome': model['nome'],\n",
        "                           'Acurácia': acuracia,\n",
        "                           'Acurácia Balanceada': acuracia_balanceada,\n",
        "                           'Precisão': precisao,\n",
        "                           'Recall': recall,\n",
        "                           'F1-score': f1,\n",
        "                           'F1-score Balanceada': f1_balanceada,\n",
        "                           'Matriz de Confusão': matriz_confusao,\n",
        "                           'Predição': y_pred\n",
        "                           })\n",
        "        # Salvar o modelo treinado usando joblib\n",
        "        model_filename = f\"modelo_{model['nome']}_treinado_sim_0.joblib\"\n",
        "        joblib.dump(x, model_filename)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pgp4lU-uaHus",
        "outputId": "78c14597-e945-41c8-8c80-fef9ee2890d1"
      },
      "outputs": [],
      "source": [
        "modelos_df2 = pd.DataFrame(resultados2)\n",
        "modelos_df2 = modelos_df2[['Nome', 'Acurácia','Acurácia Balanceada','Precisão', 'Recall', 'F1-score','F1-score Balanceada', 'Matriz de Confusão','Predição']]\n",
        "\n",
        "\n",
        "modelos_df2.head()\n",
        "\n",
        "modelos_df2.to_csv('modelos_sim_sim_0.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT9xj5aXXx79"
      },
      "source": [
        "###Classificador sim/real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJOrbdIUaXhy"
      },
      "outputs": [],
      "source": [
        "class ModeloAuxiliar(object):\n",
        "    def __init__(self, clf, seed=27, params=None):\n",
        "        if params:\n",
        "            params['random_state'] = seed\n",
        "            self.clf = clf(**params)\n",
        "        else:\n",
        "            self.clf = clf()\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        return self.clf.fit(x, y)\n",
        "\n",
        "    def feature_importances(self, x, y):\n",
        "        return self.clf.fit(x, y).feature_importances_\n",
        "\n",
        "modelos = [{'nome': 'logreg',\n",
        "           'modelo': LogisticRegression},\n",
        "           {'nome': 'KNN',\n",
        "            'modelo': KNeighborsClassifier},\n",
        "           {'nome': 'GaussianNB',\n",
        "            'modelo': GaussianNB},\n",
        "           {'nome': 'Perceptron',\n",
        "           'modelo': Perceptron},\n",
        "           {'nome': 'LinearSVC',\n",
        "            'modelo': LinearSVC},\n",
        "           {'nome': 'SGD',\n",
        "            'modelo': SGDClassifier},\n",
        "           {'nome': 'Dtree',\n",
        "            'modelo': DecisionTreeClassifier},\n",
        "           {'nome': 'RForest',\n",
        "            'modelo': RandomForestClassifier},\n",
        "           {'nome': 'ADA',\n",
        "            'modelo': AdaBoostClassifier},\n",
        "           {'nome': 'GBC',\n",
        "            'modelo': GradientBoostingClassifier},\n",
        "           {'nome': 'ETC',\n",
        "            'modelo': ExtraTreesClassifier},\n",
        "\n",
        "          ]\n",
        "\n",
        "resultados = []\n",
        "medias_acuracias = []\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in range(len(combinacoes_Xsr)):\n",
        "    X_teste, X_treino = combinacoes_Xsr[i]\n",
        "    y_teste, y_treino = combinacoes_ysr[i]\n",
        "\n",
        "    X_treino_scaled = scaler.fit_transform(X_treino)\n",
        "    X_teste_scaled = scaler.transform(X_teste)\n",
        "\n",
        "    acuracias = []\n",
        "\n",
        "    for model in modelos:\n",
        "        x = ModeloAuxiliar(clf=model['modelo'])\n",
        "\n",
        "        # treinar o modelo\n",
        "        x.fit(X_treino_scaled, y_treino)\n",
        "\n",
        "        # gerar previsão\n",
        "        y_pred = x.predict(X_teste_scaled)\n",
        "\n",
        "        # calcular a acurácia\n",
        "        acuracia = accuracy_score(y_teste, y_pred)\n",
        "\n",
        "        acuracias.append(acuracia)\n",
        "\n",
        "       # Calcula a acurácia balanceada\n",
        "\n",
        "        acuracia_balanceada = balanced_accuracy_score(y_teste, y_pred)\n",
        "\n",
        "        # Calcular a f1 balanceada\n",
        "\n",
        "        f1_balanceada = f= f1_score(y_teste, y_pred, average='weighted')\n",
        "\n",
        "        # calcular as demaism métricas\n",
        "        precisao = precision_score(y_teste, y_pred)\n",
        "        recall = recall_score(y_teste, y_pred)\n",
        "        f1 = f1_score(y_teste, y_pred)\n",
        "        matriz_confusao = confusion_matrix(y_teste, y_pred)\n",
        "\n",
        "        resultados.append({'Nome': model['nome'],\n",
        "                           'Acurácia': acuracia,\n",
        "                           'Acurácia Balanceada': acuracia_balanceada,\n",
        "                           'Precisão': precisao,\n",
        "                           'Recall': recall,\n",
        "                           'F1-score': f1,\n",
        "                           'F1-score Balanceada': f1_balanceada,\n",
        "                           'Matriz de Confusão': matriz_confusao,\n",
        "                           'Predição': y_pred\n",
        "                           })\n",
        "        # Salvar o modelo treinado usando joblib\n",
        "        model_filename = f\"modelo_{model['nome']}_treinado_real_sim_0.joblib\"\n",
        "        joblib.dump(x, model_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C9aApDZAOGkn",
        "outputId": "05b8917a-2cf1-454e-f9bb-143400c4ac89"
      },
      "outputs": [],
      "source": [
        "modelos_df = pd.DataFrame(resultados)\n",
        "modelos_df = modelos_df[['Nome', 'Acurácia','Acurácia Balanceada','Precisão', 'Recall', 'F1-score','F1-score Balanceada', 'Matriz de Confusão','Predição']]\n",
        "\n",
        "\n",
        "\n",
        "modelos_df.to_csv('modelos_sim_real_0.csv)', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NPR7AKXU3oGu"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
